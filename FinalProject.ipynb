{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9976209,"sourceType":"datasetVersion","datasetId":6138234},{"sourceId":9976416,"sourceType":"datasetVersion","datasetId":6138379},{"sourceId":9976557,"sourceType":"datasetVersion","datasetId":6138474},{"sourceId":174389,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":148467,"modelId":170986},{"sourceId":174415,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":148493,"modelId":171013},{"sourceId":174423,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":148501,"modelId":171021},{"sourceId":176297,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":150112,"modelId":172603}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nayanca12/final-project?scriptVersionId=210641272\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pytesseract\nfrom ultralytics import YOLO\nimport cv2\nimport openpyxl\nimport os\nimport sqlite3\nfrom ultralytics.utils.plotting import Annotator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:49:17.555903Z","iopub.execute_input":"2024-12-01T14:49:17.556418Z","iopub.status.idle":"2024-12-01T14:49:17.562585Z","shell.execute_reply.started":"2024-12-01T14:49:17.556357Z","shell.execute_reply":"2024-12-01T14:49:17.561199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics\n!pip install opencv-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:49:27.859897Z","iopub.execute_input":"2024-12-01T14:49:27.860308Z","iopub.status.idle":"2024-12-01T14:49:48.888639Z","shell.execute_reply.started":"2024-12-01T14:49:27.860276Z","shell.execute_reply":"2024-12-01T14:49:48.887025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install pytesseract","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:48:44.70389Z","iopub.execute_input":"2024-11-23T15:48:44.704359Z","iopub.status.idle":"2024-11-23T15:48:54.886764Z","shell.execute_reply.started":"2024-11-23T15:48:44.704319Z","shell.execute_reply":"2024-11-23T15:48:54.885229Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm /opt/conda/lib/libcurl.so.4 \n!ln -s /usr/lib/x86_64-linux-gnu/libcurl.so.4.8.0 /opt/conda/lib/libcurl.so.4\n!add-apt-repository ppa:alex-p/tesseract-ocr5 -y\n!apt update\n!apt install -y tesseract-ocr\n!apt install tesseract-ocr-eng\n# If you want all languages -- please note this will take time to download. You could also point to the already install tessdata in 4.00 as well.\n# !apt install tesseract-ocr-all -y\n!tesseract --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:35:37.607041Z","iopub.execute_input":"2024-12-01T14:35:37.607468Z","iopub.status.idle":"2024-12-01T14:36:11.968549Z","shell.execute_reply.started":"2024-12-01T14:35:37.607434Z","shell.execute_reply":"2024-12-01T14:36:11.967176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from platform import python_version\n\nprint(python_version())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:50:06.160641Z","iopub.execute_input":"2024-12-01T14:50:06.161958Z","iopub.status.idle":"2024-12-01T14:50:06.169139Z","shell.execute_reply.started":"2024-12-01T14:50:06.1619Z","shell.execute_reply":"2024-12-01T14:50:06.167864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to create the table if it doesn't exist\ndef create_table():\n    # Connect to the SQLite database\n    conn = sqlite3.connect(\"numberplate.db\")\n    # Create a cursor object to execute SQL statements\n    c = conn.cursor()\n    # Create the \"vehicles\" table with two columns: \"vehicle_number\" and \"bike_image_path\"\n    # The \"IF NOT EXISTS\" clause ensures that the table is only created if it doesn't already exist\n    c.execute(\"CREATE TABLE IF NOT EXISTS vehicles (vehicle_number TEXT, bike_image_path TEXT)\")\n    # Commit the changes to the database\n    conn.commit()\n    # Close the database connection\n    conn.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:52:47.026855Z","iopub.execute_input":"2024-12-01T14:52:47.027321Z","iopub.status.idle":"2024-12-01T14:52:47.035509Z","shell.execute_reply.started":"2024-12-01T14:52:47.027283Z","shell.execute_reply":"2024-12-01T14:52:47.03365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to insert a record into the \"vehicles\" table\ndef insert_record(vehicle_number, bike_image_path):\n    # Connect to the SQLite database\n    conn = sqlite3.connect(\"numberplate.db\")\n    # Create a cursor object to execute SQL statements\n    c = conn.cursor()\n    # Insert the record into the \"vehicles\" table using parameterized SQL statement\n    c.execute(\"INSERT INTO vehicles VALUES (?, ?)\", (vehicle_number, bike_image_path))\n    # Commit the changes to the database\n    conn.commit()\n    # Close the database connection\n    conn.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:53:10.461808Z","iopub.execute_input":"2024-12-01T14:53:10.462248Z","iopub.status.idle":"2024-12-01T14:53:10.469632Z","shell.execute_reply.started":"2024-12-01T14:53:10.462216Z","shell.execute_reply":"2024-12-01T14:53:10.468138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# workbook = openpyxl.Workbook()\n# worksheet = workbook.active","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def write_to_excel(text, image_path):\n#     worksheet.append([text, image_path])\n#     workbook.save(\"C:/Users/PRAJWAL M/Registration_Plate_Recognition - Copy/Book1.xlsx\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Initialize YOLO models\n# person_bike_model = YOLO(r\"C:/Users/PRAJWAL M/Desktop/main_model/300epoch.pt\")\n# helmet_model = YOLO(r\"C:/Users/PRAJWAL M/Desktop/bike-helmet model/300epoch_bh.pt\")\n# number_plate_model = YOLO(r\"C:/Users/PRAJWAL M/Desktop/vehicle model/300epochv.pt\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize YOLO models\nperson_bike_model = YOLO(\"/kaggle/input/person_on_bike_model/pytorch/default/1/best.pt\")\nhelmet_model = YOLO(\"/kaggle/input/helmet_model/pytorch/default/1/best.pt\")\nnumber_plate_model = YOLO(\"/kaggle/input/numberplate_model/pytorch/default/1/300epochv.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:50:15.134325Z","iopub.execute_input":"2024-12-01T14:50:15.134833Z","iopub.status.idle":"2024-12-01T14:50:15.506675Z","shell.execute_reply.started":"2024-12-01T14:50:15.134796Z","shell.execute_reply":"2024-12-01T14:50:15.505188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up Tesseract OCR\npytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\nayan\\OneDrive\\Desktop\\Tesseract_download\\Tesseract-OCR\\tesseract.exe\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:44:24.454642Z","iopub.execute_input":"2024-11-23T15:44:24.455135Z","iopub.status.idle":"2024-11-23T15:44:24.460443Z","shell.execute_reply.started":"2024-11-23T15:44:24.455098Z","shell.execute_reply":"2024-11-23T15:44:24.459171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Check OCR\nimage_path = \"/kaggle/input/testtt/WhatsApp Image 2024-11-21 at 13.01.29_69035291.jpg\"\nframe = cv2.imread(image_path)\ntext = pytesseract.image_to_string(frame)\n# cv2.imshow(\"window\",frame)\nprint(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:50:19.971563Z","iopub.execute_input":"2024-12-01T14:50:19.972075Z","iopub.status.idle":"2024-12-01T14:50:20.4506Z","shell.execute_reply.started":"2024-12-01T14:50:19.972036Z","shell.execute_reply":"2024-12-01T14:50:20.448957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = \"/kaggle/input/imagee\"\n# frame = cv2.imread(image_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:50:26.735962Z","iopub.execute_input":"2024-12-01T14:50:26.736429Z","iopub.status.idle":"2024-12-01T14:50:26.742073Z","shell.execute_reply.started":"2024-12-01T14:50:26.736391Z","shell.execute_reply":"2024-12-01T14:50:26.740647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#tesseract ocr alternative\n# import easyocr\n\n# reader = easyocr.Reader(['en'])\n# extract_info = reader.readtext(image_path)\n\n# for el in extract_info:\n#    print(el)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# output_dir = r\"C:/Users/PRAJWAL M/Registration_Plate_Recognition - Copy/output\"  # Directory to save the output images for image folder\noutput_dir = \"/kaggle/working/\"  # Directory to save the output images for image folder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:40:32.439873Z","iopub.execute_input":"2024-12-01T14:40:32.440353Z","iopub.status.idle":"2024-12-01T14:40:32.446054Z","shell.execute_reply.started":"2024-12-01T14:40:32.440313Z","shell.execute_reply":"2024-12-01T14:40:32.444736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_dir1 = r\"C:/Users/PRAJWAL M/Registration_Plate_Recognition - Copy/newoutput\"  # Directory to save the output images for video input","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model test\nperson_bike_results = person_bike_model.predict(image_path, show=True, save=True)\nh_results = helmet_model.predict(image_path, show=True, save=True)\nn_results = number_plate_model.predict(image_path, show=True, save=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:50:32.020926Z","iopub.execute_input":"2024-12-01T14:50:32.021454Z","iopub.status.idle":"2024-12-01T14:50:33.796159Z","shell.execute_reply.started":"2024-12-01T14:50:32.02141Z","shell.execute_reply":"2024-12-01T14:50:33.795434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Path to the folder containing images\ninput_folder = \"/kaggle/input/newdata/otest\"\n\n\n# Get a list of all image files in the input folder\nimage_files = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith(('.jpg', '.jpeg', '.png'))]\n\n# Process each image in the folder\nfor image_file in image_files:\n    # Load the image\n    img = cv2.imread(image_file)\n\n    # Process frame\n    #img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    # Detect person on a bike\n    person_bike_results = person_bike_model.predict(img, show=True, save=True)\n    \n    # Process each detection result\n    for r in person_bike_results:\n        boxes = r.boxes\n        # Filter detections for person on a bike\n        for box in boxes:\n            cls = box.cls\n            print(person_bike_model.names[int(cls)], person_bike_model.names[int(cls)] == \"person_bike\")\n            if person_bike_model.names[int(cls)] == \"person_bike\":\n                # Crop person on a bike image\n                x1, y1, x2, y2 = box.xyxy[0]\n                person_bike_image = img[int(y1):int(y2), int(x1):int(x2)]\n\n                # Detect helmet on the person\n                helmet_results = helmet_model.predict(person_bike_image, show=True, save=True)\n\n                # Process each helmet detection result\n                for hr in helmet_results:\n                    h_boxes = hr.boxes\n                    # Filter detections for no helmet\n                    for h_bo in h_boxes:\n                        h_cls = h_bo.cls\n                        if not helmet_model.names[int(h_cls)] == \"With Helmet\" :\n                            # Extract number plate from the person bike image\n                            number_plate_results = number_plate_model.predict(person_bike_image, show=True, save=True)\n\n                            # Process each number plate detection result\n                            for npr in number_plate_results:\n                                np_boxes = npr.boxes\n                                # Filter detections for number plate\n                                for np_box in np_boxes:\n                                    np_cls = np_box.cls\n                                    print(number_plate_model.names[int(np_cls)])\n                                    if number_plate_model.names[int(np_cls)] == \"License_Plate\":\n                                        # Crop number plate image\n                                        np_x1, np_y1, np_x2, np_y2 = np_box.xyxy[0]\n                                        number_plate_image = person_bike_image[int(np_y1):int(np_y2),\n                                                             int(np_x1):int(np_x2)]\n                                        # Save the cropped images of persons on bikes with violations\n                                        output_file = f\"person_bike_violation_{os.path.basename(image_file)}\"\n                                        output_path = os.path.join(output_dir, output_file)\n                                        cv2.imwrite(output_path, person_bike_image)\n\n                                        # Save the cropped number plate image\n                                        output_file_number_plate = f\"number_plate_violation_{os.path.basename(image_file)}\"\n                                        output_path_number_plate = os.path.join(output_dir, output_file_number_plate)\n                                        cv2.imwrite(output_path_number_plate, number_plate_image)\n                                        gray = cv2.cvtColor(number_plate_image, cv2.COLOR_BGR2GRAY)\n                                        text = pytesseract.image_to_string(gray)\n                                        # Example usage\n                                        # Create the \"vehicles\" table if it doesn't exist\n                                        create_table()\n                                        # Insert two records into the \"vehicles\" table\n                                        insert_record(text, output_path)\n                                        # Print the extracted text\n                                        print(\"Number Plate Text:\", text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T14:53:32.581632Z","iopub.execute_input":"2024-12-01T14:53:32.582133Z","iopub.status.idle":"2024-12-01T14:53:33.115428Z","shell.execute_reply.started":"2024-12-01T14:53:32.582091Z","shell.execute_reply":"2024-12-01T14:53:33.113322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# video_capture = cv2.VideoCapture(\"C:/Users/PRAJWAL M/Desktop/testing/VID_20240322_135640.mp4\")  \nvideo_capture = cv2.VideoCapture(\"C:/Users/PRAJWAL M/Desktop/Untitled video - Made with Clipchamp.mp4\")\nwhile True:\n    # Capture frame-by-frame\n    ret, frame = video_capture.read()\n    # Process frame\n    #img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    # Detect person on a bike\n    person_bike_results = person_bike_model.predict(frame)\n\n    # Process each detection result\n    for r in person_bike_results:\n        boxes = r.boxes\n        # Filter detections for person on a bike\n        for box in boxes:\n            cls = box.cls\n            print(person_bike_model.names[int(cls)], person_bike_model.names[int(cls)] == \"person_bike\")\n            if person_bike_model.names[int(cls)] == \"person_bike\":\n                # Crop person on a bike image\n                x1, y1, x2, y2 = box.xyxy[0]\n                person_bike_image = frame[int(y1):int(y2), int(x1):int(x2)]\n\n                # Detect helmet on the person\n                helmet_results = helmet_model.predict(person_bike_image)\n\n                # Process each helmet detection result\n                for hr in helmet_results:\n                    h_boxes = hr.boxes\n                    # Filter detections for no helmet\n                    for h_bo in h_boxes:\n                        h_cls = h_bo.cls\n                        if not helmet_model.names[int(h_cls)] == \"With Helmet\" :\n                            # Extract number plate from the person bike image\n                            number_plate_results = number_plate_model.predict(person_bike_image)\n\n                            # Process each number plate detection result\n                            for npr in number_plate_results:\n                                np_boxes = npr.boxes\n                                # Filter detections for number plate\n                                for np_box in np_boxes:\n                                    np_cls = np_box.cls\n                                    print(number_plate_model.names[int(np_cls)])\n                                    if number_plate_model.names[int(np_cls)] == \"License_Plate\":\n                                        # Crop number plate image\n                                        np_x1, np_y1, np_x2, np_y2 = np_box.xyxy[0]\n                                        number_plate_image = person_bike_image[int(np_y1):int(np_y2),\n                                                             int(np_x1):int(np_x2)]\n                                        # Save the cropped number plate image\n                                        #output_file = f\"person_violation_{image_file}\"\n                                        output_file = f\"person_bike_violation_{os.path.basename(image_file)}\"\n                                        output_path = os.path.join(output_dir1, output_file)\n                                        cv2.imwrite(output_path, person_bike_image)\n\n                                        # Perform OCR on the number plate image\n                                        gray = cv2.cvtColor(number_plate_image, cv2.COLOR_BGR2GRAY)\n                                        text = pytesseract.image_to_string(gray)\n                                        # Example usage\n                                        # Create the \"vehicles\" table if it doesn't exist\n                                        create_table()\n                                        # Insert two records into the \"vehicles\" table\n                                        insert_record(text, output_path)\n                                        # Print the extracted text\n                                        print(\"Number Plate Text:\", text)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}